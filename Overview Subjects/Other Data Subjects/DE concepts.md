all systems store data in files â€” Snowflake, SQL Server, Databricks, Oracle, etc. Each system uses formats it can understand and process efficiently.

But the real, technical distinction of a database isnâ€™t just about "storing files." Itâ€™s about who owns and manages the data lifecycle and how tightly integrated that is with the execution engine and metadata catalog.

âœ… The Real Differentiators of a Database
Letâ€™s define what makes something a "database" in a technical and architectural sense â€” even if all systems use files.

1. Ownership and Opacity of Storage
Aspect	Databases (e.g., Snowflake, SQL Server)	Lakehouses (e.g., Databricks, Iceberg)
Who owns the storage?	The engine (you donâ€™t touch internal files)	You (you manage the Parquet/ORC files yourself)
Is the file format opaque?	Yes â€” proprietary columnar or page format	No â€” Parquet/ORC files are open and readable
Can I use other engines?	No â€” storage is not meant to be reused	Yes â€” same files can be queried by many engines

âœ… Databases "own" your data. You canâ€™t open a Snowflake or SQL Server file and process it with Spark.

âŒ Lakehouses give you full control â€” your data is accessible and queryable across tools.

2. Data Management Responsibility
Feature	Database	Lakehouse
Query engine tightly bound	Yes â€” engine/storage are one system	No â€” engines are separate (Spark, Trino, etc.)
Automatic indexing	Yes (e.g., SQL Server B-trees, metadata)	No (you tune manually or use optimizations)
Automatic stats/catalog	Yes â€” always updated internally	No â€” sometimes manual or eventually consistent
ACID enforcement	Centralized via transaction log	File-based log (Delta, Iceberg) across systems

âœ… A database manages data placement, indexing, stats, concurrency â€” you donâ€™t need to think about the physical layer.

âŒ In lakehouses, you're expected to optimize and manage file layout, compaction, schema evolution, etc.

3. Tightly Coupled Execution + Metadata + Storage
A true database is a vertically integrated stack:

pgsql
Copier
Modifier
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SQL Engine   â”‚  <-- tightly coupled
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Query Plannerâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Transaction  â”‚
â”‚ Manager      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Metadata     â”‚  <-- stored internally
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Storage Layerâ”‚  <-- controlled, not user-facing
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
By contrast, a lakehouse (Databricks + Delta) is decoupled:

scss
Copier
Modifier
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Engine â”‚ <-->  â”‚ Metadata Log â”‚ (Delta)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†•
   Cloud Storage (you manage the files)
This distinction is critical.

âœ… So: Why Is Snowflake a Database and Databricks Not (Strictly Speaking)?
Feature	Snowflake (Database)	Databricks with Delta Lake
Owns internal file storage	âœ… Yes â€” not user-accessible	âŒ No â€” user manages files in S3/ADLS
Proprietary storage format	âœ… Yes â€” columnar, compressed, encrypted	âŒ No â€” open formats like Parquet
One engine to read/write data	âœ… Yes (Snowflake engine only)	âŒ No â€” Spark, Trino, Presto, etc.
Tightly coupled metadata	âœ… Yes â€” Snowflake catalogs only	âŒ No â€” Delta log + optional Hive metastore
User file access	âŒ No	âœ… Yes â€” full access and control
Query portability	âŒ Not portable	âœ… Portable across engines

ğŸ’¡ Analogy: Think of a Database as an Appliance
You give it data.

It stores, manages, optimizes, indexes, secures, and queries it.

You donâ€™t see or control the parts inside â€” it's optimized for one purpose.

A lakehouse is more like a toolbox:

You decide where to store the data.

You decide how to organize it.

You can use different tools (Spark, Trino) to access it.

You're responsible for optimizations (Z-ordering, compaction, etc.).

ğŸ”„ But Isnâ€™t Databricks Becoming More Database-Like?
Yes, especially with Unity Catalog, transaction management, and Delta optimizations, Databricks is blurring the line. It's turning its lakehouse into a database-like experience, but:

The underlying architecture remains open and decoupled.

You still own and can access your Parquet files directly.

ğŸ”š Final Summary
What makes something a database isnâ€™t just "it uses files" or "you can query with SQL" â€” it's:

âœ… Central ownership of storage
âœ… Tightly integrated query, metadata, and transaction layers
âœ… No external access to internal files
âœ… Automated data management and optimization
